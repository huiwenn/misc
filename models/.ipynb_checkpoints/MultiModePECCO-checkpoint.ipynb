{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:36.254565Z",
     "start_time": "2021-05-05T16:44:35.819884Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import argoverse\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('./')\n",
    "sys.path.append('../')\n",
    "\n",
    "from EquiCtsConv import *\n",
    "from EquiLinear import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:54:51.692527Z",
     "start_time": "2021-05-05T16:54:51.678277Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_enabled() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a9970202643d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWarning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_enabled() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "torch.utils.backcompat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:36.258212Z",
     "start_time": "2021-05-05T16:44:36.255822Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:36.426429Z",
     "start_time": "2021-05-05T16:44:36.409037Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class VehicleEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_radii = 3, \n",
    "                 num_theta = 16, \n",
    "                 reg_dim = 8,\n",
    "                 radius_scale = 40,\n",
    "                 timestep = 0.1,\n",
    "                 in_channel = 19, \n",
    "                 layer_channels = [8, 16, 16]\n",
    "                 ):\n",
    "        super(VehicleEncoder, self).__init__()\n",
    "        \n",
    "        # init parameters\n",
    "        \n",
    "        self.num_radii = num_radii\n",
    "        self.num_theta = num_theta\n",
    "        self.reg_dim = reg_dim\n",
    "        self.radius_scale = radius_scale\n",
    "        self.timestep = timestep\n",
    "        self.layer_channels = layer_channels\n",
    "        \n",
    "        self.in_channel = in_channel\n",
    "        self.activation = F.relu\n",
    "        # self.relu_shift = torch.nn.parameter.Parameter(torch.tensor(0.2))\n",
    "        # relu_shift = torch.tensor(0.2)\n",
    "        # self.register_buffer('relu_shift', relu_shift)\n",
    "        \n",
    "        # create continuous convolution and fully-connected layers\n",
    "        \n",
    "        convs = []\n",
    "        denses = []\n",
    "        # c_in, c_out, radius, num_radii, num_theta\n",
    "        self.conv_vehicle = EquiCtsConv2dRho1ToReg(in_channels = self.in_channel, \n",
    "                                                 out_channels = self.layer_channels[0],\n",
    "                                                 num_radii = self.num_radii, \n",
    "                                                 num_theta = self.num_theta,\n",
    "                                                 radius = self.radius_scale, \n",
    "                                                 k = self.reg_dim)\n",
    "\n",
    "        self.dense_vehicle = nn.Sequential(\n",
    "            EquiLinearRho1ToReg(self.reg_dim), \n",
    "            EquiLinearRegToReg(self.in_channel, self.layer_channels[0], self.reg_dim)\n",
    "        )\n",
    "        \n",
    "        # concat conv_obstacle, conv_fluid, dense_fluid\n",
    "        in_ch = 2 * self.layer_channels[0] \n",
    "        for i in range(1, len(self.layer_channels)):\n",
    "            out_ch = self.layer_channels[i]\n",
    "            dense = EquiLinearRegToReg(in_ch, out_ch, self.reg_dim)\n",
    "            denses.append(dense)\n",
    "            conv = EquiCtsConv2dRegToReg(in_channels = in_ch, \n",
    "                                         out_channels = out_ch,\n",
    "                                         num_radii = self.num_radii, \n",
    "                                         num_theta = self.num_theta,\n",
    "                                         radius = self.radius_scale, \n",
    "                                         k = self.reg_dim)\n",
    "            convs.append(conv)\n",
    "            in_ch = self.layer_channels[i]\n",
    "        \n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.denses = nn.ModuleList(denses)\n",
    "        \n",
    "\n",
    "    def encode(self, p, vehicle_feats, car_mask):\n",
    "\n",
    "        output_conv_vehicle = self.conv_vehicle(p, p, vehicle_feats, car_mask)\n",
    "        output_dense_vehicle = self.dense_vehicle(vehicle_feats)\n",
    "        \n",
    "        output = torch.cat((output_conv_vehicle, output_dense_vehicle), -2)\n",
    "        \n",
    "        for conv, dense in zip(self.convs, self.denses):\n",
    "            # pass input features to conv and fully-connected layers\n",
    "            # mags = (torch.sum(output**2,axis=-1) + 1e-6).unsqueeze(-1)\n",
    "            # in_feats = output/mags * self.activation(mags - self.relu_shift)\n",
    "            in_feats = self.activation(output)\n",
    "            output_conv = conv(p, p, in_feats, car_mask)\n",
    "            output_dense = dense(in_feats)\n",
    "            \n",
    "            if output_dense.shape[-2] == output.shape[-2]:\n",
    "                output = output_conv + output_dense + output\n",
    "            else:\n",
    "                output = output_conv + output_dense\n",
    "\n",
    "        output = self.activation(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\" inputs: 8 elems tuple\n",
    "        p0_enc, v0_enc, p0, v0, feats, box, box_feats\n",
    "        v0_enc: [batch, num_part, timestamps, 2]\n",
    "        \"\"\"\n",
    "        p0_enc, v0_enc, p0, v0, car_mask = inputs\n",
    "            \n",
    "        feats = torch.cat((v0.unsqueeze(-2), v0_enc), -2)\n",
    "\n",
    "        hidden_feature = self.encode(p0, feats, car_mask)\n",
    "\n",
    "        return hidden_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:36.438760Z",
     "start_time": "2021-05-05T16:44:36.433128Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MapEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_radii = 3, \n",
    "                 num_theta = 16, \n",
    "                 reg_dim = 8,\n",
    "                 radius_scale = 40,\n",
    "                 hidden_size: int = 8\n",
    "                 ):\n",
    "        super(MapEncoder, self).__init__()\n",
    "        \n",
    "        # init parameters\n",
    "        \n",
    "        self.num_radii = num_radii\n",
    "        self.num_theta = num_theta\n",
    "        self.reg_dim = reg_dim\n",
    "        self.radius_scale = radius_scale\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.activation = F.relu\n",
    "        # self.relu_shift = torch.nn.parameter.Parameter(torch.tensor(0.2))\n",
    "        # relu_shift = torch.tensor(0.2)\n",
    "        # self.register_buffer('relu_shift', relu_shift)\n",
    "        \n",
    "        # create continuous convolution and fully-connected layers\n",
    "        \n",
    "        # c_in, c_out, radius, num_radii, num_theta\n",
    "        self.conv_map = EquiCtsConv2dRho1ToReg(in_channels = 1, \n",
    "                                               out_channels = self.hidden_size,\n",
    "                                               num_radii = self.num_radii, \n",
    "                                               num_theta = self.num_theta,\n",
    "                                               radius = self.radius_scale, \n",
    "                                               k = self.reg_dim)\n",
    "\n",
    "    def forward(self, p, map_p, map_feat, map_mask):\n",
    "        \n",
    "        output = self.conv_map(map_p, p, map_feat.unsqueeze(-2), map_mask)\n",
    "        \n",
    "        output = self.activation(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:36.641621Z",
     "start_time": "2021-05-05T16:44:36.633257Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ModeDecoder(nn.Module):\n",
    "    def __init__(self, vehicle_hidden=16, map_hidden=8, reg_dim=8, modes=6):\n",
    "        super(ModeDecoder, self).__init__()\n",
    "        in_channel = vehicle_hidden + map_hidden\n",
    "        self.modes = modes\n",
    "        if modes == 1:\n",
    "            self.mode_decoder = lambda x: None\n",
    "        else:\n",
    "            self.mode_decoder = EquiLinearRegToReg(in_channel, modes, reg_dim)\n",
    "        \n",
    "    def forward(self, feat):\n",
    "        \"\"\"\n",
    "        feat: shape (batch, num_vehicles, v+m, reg_dim)\n",
    "        \n",
    "        return: shape (batch, modes)\n",
    "        \"\"\"\n",
    "        if self.modes == 1:\n",
    "            return self.mode_decoder(feat)\n",
    "        else:\n",
    "            # mode_pred, _ = self.mode_decoder(feat).norm(dim=-1).topk(k=1, dim=1)\n",
    "            # mode_pred = mode_pred.squeeze(1)\n",
    "            mode_pred = self.mode_decoder(feat).norm(dim=-1).permute(0,2,1)\n",
    "            mode_pred = F.max_pool1d(mode_pred, mode_pred.shape[-1]).squeeze(-1)\n",
    "            return F.softmax(mode_pred, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:36.872912Z",
     "start_time": "2021-05-05T16:44:36.853275Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class TrajectoryDecoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_radii = 3, \n",
    "                 num_theta = 16, \n",
    "                 reg_dim = 8,\n",
    "                 radius_scale = 40,\n",
    "                 timestep = 0.1,\n",
    "                 vehicle_hidden = 16, \n",
    "                 map_hidden = 8,\n",
    "                 layer_channels = [8, 8, 3], \n",
    "                 predict_window = 30, \n",
    "                 map_encoder = None\n",
    "                 ):\n",
    "        super(TrajectoryDecoder, self).__init__()\n",
    "        \n",
    "        # init parameters\n",
    "        \n",
    "        self.num_radii = num_radii\n",
    "        self.num_theta = num_theta\n",
    "        self.reg_dim = reg_dim\n",
    "        self.radius_scale = radius_scale\n",
    "        self.timestep = timestep\n",
    "        self.predict_window = predict_window\n",
    "        self.vehicle_hidden = vehicle_hidden\n",
    "        self.map_hidden = map_hidden\n",
    "        self.layer_channels = layer_channels\n",
    "        \n",
    "        self.in_channel = vehicle_hidden + map_hidden\n",
    "        self.activation = F.relu\n",
    "        # self.relu_shift = torch.nn.parameter.Parameter(torch.tensor(0.2))\n",
    "        # relu_shift = torch.tensor(0.2)\n",
    "        # self.register_buffer('relu_shift', relu_shift)\n",
    "        \n",
    "        # create continuous convolution and fully-connected layers\n",
    "        \n",
    "        convs = []\n",
    "        denses = []\n",
    "        # c_in, c_out, radius, num_radii, num_theta\n",
    "        self.conv_vehicle = EquiCtsConv2dRegToReg(in_channels = self.in_channel, \n",
    "                                                   out_channels = self.layer_channels[0],\n",
    "                                                   num_radii = self.num_radii, \n",
    "                                                   num_theta = self.num_theta,\n",
    "                                                   radius = self.radius_scale, \n",
    "                                                   k = self.reg_dim)\n",
    "        \n",
    "        if map_encoder:\n",
    "            self.map_encoder = map_encoder\n",
    "        else:\n",
    "            self.map_encoder = MapEncoder(num_radii = num_radii, \n",
    "                                          num_theta = num_theta, \n",
    "                                          reg_dim = reg_dim,\n",
    "                                          radius_scale = radius_scale,\n",
    "                                          hidden_size = map_hidden)\n",
    "\n",
    "        self.dense_vehicle = EquiLinearRegToReg(self.in_channel, self.layer_channels[0], self.reg_dim)\n",
    "        \n",
    "        # concat conv_obstacle, conv_fluid, dense_fluid\n",
    "        in_ch = self.layer_channels[0] \n",
    "        for i in range(1, len(self.layer_channels)):\n",
    "            out_ch = self.layer_channels[i]\n",
    "            dense = EquiLinearRegToReg(in_ch, out_ch, self.reg_dim)\n",
    "            denses.append(dense)\n",
    "            conv = EquiCtsConv2dRegToReg(in_channels = in_ch, \n",
    "                                         out_channels = out_ch,\n",
    "                                         num_radii = self.num_radii, \n",
    "                                         num_theta = self.num_theta,\n",
    "                                         radius = self.radius_scale, \n",
    "                                         k = self.reg_dim)\n",
    "            convs.append(conv)\n",
    "            in_ch = self.layer_channels[i]\n",
    "        \n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.denses = nn.ModuleList(denses)\n",
    "        \n",
    "        self.dense_back = EquiLinearRegToReg(self.layer_channels[-1], vehicle_hidden, self.reg_dim)\n",
    "        self.dense_reg2rho1 = EquiLinearRegToRho1(self.reg_dim)\n",
    "        \n",
    "    def decode(self, p, feat, map_p, map_feat, car_mask, map_mask):\n",
    "        output_conv_vehicle = self.conv_vehicle(p, p, feat, car_mask)\n",
    "        output_dense_vehicle = self.dense_vehicle(feat)\n",
    "        \n",
    "        output = output_conv_vehicle + output_dense_vehicle\n",
    "        \n",
    "        for conv, dense in zip(self.convs, self.denses):\n",
    "            # pass input features to conv and fully-connected layers\n",
    "            # mags = (torch.sum(output**2,axis=-1) + 1e-6).unsqueeze(-1)\n",
    "            # in_feats = output/mags * self.activation(mags - self.relu_shift)\n",
    "            in_feats = self.activation(output)\n",
    "            output_conv = conv(p, p, in_feats, car_mask)\n",
    "            output_dense = dense(in_feats)\n",
    "            \n",
    "            if output_dense.shape[-2] == output.shape[-2]:\n",
    "                output = output_conv + output_dense + output\n",
    "            else:\n",
    "                output = output_conv + output_dense\n",
    "\n",
    "        output = self.activation(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def forward(self, p, feat, map_p, map_feat, car_mask, map_mask):\n",
    "        outputs = []\n",
    "        \n",
    "        output = self.decode(p, feat, map_p, map_feat, car_mask, map_mask)\n",
    "        delta_p_dist = self.dense_reg2rho1(output)\n",
    "        pred = delta_p_dist.clone()\n",
    "        pred[...,0,:] = pred[...,0,:] + p\n",
    "        outputs.append(pred)\n",
    "        \n",
    "        for t in range(1, self.predict_window):\n",
    "            p = p + delta_p_dist[...,0,:]\n",
    "            back_feat = torch.tanh(self.dense_back(output))\n",
    "            \n",
    "            feat = feat[...,:self.vehicle_hidden,:] * back_feat\n",
    "            encode_map = self.map_encoder(p, map_p, map_feat, map_mask)\n",
    "            feat = torch.cat([feat, encode_map], dim=-2)\n",
    "            \n",
    "        \n",
    "            output = self.decode(p, feat, map_p, map_feat, car_mask, map_mask)\n",
    "            delta_p_dist = self.dense_reg2rho1(output)\n",
    "            pred = delta_p_dist.clone()\n",
    "            pred[...,0,:] = pred[...,0,:] + p\n",
    "            outputs.append(pred)\n",
    "            \n",
    "        return outputs\n",
    "    \n",
    "    def reset_predict_window(self, window):\n",
    "        self.predict_window = window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:45:38.798091Z",
     "start_time": "2021-05-05T16:45:38.780950Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MultiModePECCO(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_radii = 3, \n",
    "                 num_theta = 16, \n",
    "                 reg_dim = 8,\n",
    "                 radius_scale = 40,\n",
    "                 timestep = 0.1,\n",
    "                 in_channel = 19,\n",
    "                 map_hidden = 8, \n",
    "                 encoder_channels = [8, 16, 16],\n",
    "                 decoder_channels = [8, 3], \n",
    "                 predict_window = 30, \n",
    "                 modes = 6):\n",
    "        super(MultiModePECCO, self).__init__()\n",
    "        \n",
    "        self.modes = modes\n",
    "        \n",
    "        self.vehicle_encoder = VehicleEncoder(num_radii = num_radii, \n",
    "                                              num_theta = num_theta, \n",
    "                                              reg_dim = reg_dim,\n",
    "                                              radius_scale = radius_scale,\n",
    "                                              timestep = timestep,\n",
    "                                              in_channel = in_channel, \n",
    "                                              layer_channels = encoder_channels)\n",
    "        \n",
    "        self.map_encoder = MapEncoder(num_radii = num_radii, \n",
    "                                      num_theta = num_theta, \n",
    "                                      reg_dim = reg_dim,\n",
    "                                      radius_scale = radius_scale,\n",
    "                                      hidden_size = map_hidden)\n",
    "        \n",
    "        self.mode_decoder = ModeDecoder(vehicle_hidden=encoder_channels[-1], \n",
    "                                        map_hidden=map_hidden, \n",
    "                                        reg_dim=reg_dim, modes=modes)\n",
    "        \n",
    "        self.traj_decoder = []\n",
    "        for m in range(modes):\n",
    "            traj_decoder_m = TrajectoryDecoder(num_radii = num_radii, \n",
    "                                               num_theta = num_theta, \n",
    "                                               reg_dim = reg_dim,\n",
    "                                               radius_scale = radius_scale,\n",
    "                                               timestep = timestep,\n",
    "                                               vehicle_hidden = encoder_channels[-1], \n",
    "                                               map_hidden = map_hidden,\n",
    "                                               layer_channels = decoder_channels, \n",
    "                                               predict_window = predict_window, \n",
    "                                               map_encoder = self.map_encoder)\n",
    "            self.traj_decoder.append(traj_decoder_m)\n",
    "            \n",
    "        self.traj_decoder = nn.ModuleList(self.traj_decoder)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        p_enc, v_enc, p, v, map_p, map_feat, car_mask, map_mask = inputs\n",
    "        \n",
    "        vehicle_hidden = self.vehicle_encoder((p_enc, v_enc, p, v, car_mask))\n",
    "        map_hidden = self.map_encoder(p, map_p, map_feat, map_mask)\n",
    "        \n",
    "        feat = torch.cat([vehicle_hidden, map_hidden], dim=-2)\n",
    "        \n",
    "        traj_preds = []\n",
    "        for m in range(self.modes):\n",
    "            traj_pred = self.traj_decoder[m](p, feat, map_p, map_feat, car_mask, map_mask)\n",
    "            traj_preds.append(traj_pred)\n",
    "            \n",
    "        mode_pred = self.mode_decoder(feat)\n",
    "        \n",
    "        return traj_preds, mode_pred\n",
    "    \n",
    "    def reset_predict_window(self, window):\n",
    "        for m in range(self.modes):\n",
    "            self.traj_decoder[m].reset_predict_window(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:45.966436Z",
     "start_time": "2021-05-05T16:44:37.464290Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MultiModePECCO(predict_window=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:45.977881Z",
     "start_time": "2021-05-05T16:44:45.967934Z"
    }
   },
   "outputs": [],
   "source": [
    "def quadratic_func(x, M):\n",
    "    part1 = torch.einsum('...x,...xy->...y', x, M)\n",
    "    return torch.einsum('...x,...x->...', part1, x)\n",
    "\n",
    "def calc_sigma(M):\n",
    "    M1 = torch.tanh(M)\n",
    "    sigma = torch.einsum('...xy,...xz->...yz', M1, M1)\n",
    "    return torch.matrix_exp(sigma)\n",
    "\n",
    "def nll_loss(pred, gt, mask):\n",
    "    mu = pred[...,0,:]\n",
    "    # sigma = torch.einsum('...xy,...xz->...yz', pred[mask>0][...,1:,:], pred[mask>0][...,1:,:])\n",
    "    sigma = calc_sigma(pred[...,1:,:])\n",
    "    nll = quadratic_func(gt - mu, sigma.inverse()) + torch.log(sigma.det())\n",
    "    return nll * mask\n",
    "\n",
    "def nll_loss_per_sample(preds, data):\n",
    "    loss = 0\n",
    "    for i, pred in enumerate(preds):\n",
    "        loss = loss + nll_loss(pred, data['pos'+str(i+1)], data['car_mask'][...,0])\n",
    "    return loss / (i + 1)\n",
    "\n",
    "def nll_loss_multimodes(preds, data, modes_pred, noise=0.0):\n",
    "    \"\"\"NLL loss multimodes for training.\n",
    "    Args:\n",
    "        pred is a list (with N modes) of predictions\n",
    "        data is ground truth    \n",
    "        noise is optional\n",
    "    \"\"\"\n",
    "    modes = len(preds)\n",
    "    log_lik = []   \n",
    "    with torch.no_grad():\n",
    "        for pred in preds:\n",
    "            nll = nll_loss_per_sample(pred, data)\n",
    "            log_lik.append(-nll.unsqueeze(-1))\n",
    "        log_lik = torch.cat(log_lik, -1)\n",
    "  \n",
    "    priors = modes_pred.detach().unsqueeze(1)\n",
    "    print(log_lik.shape, priors.shape)\n",
    "    log_posterior_unnorm = log_lik + torch.log(priors)\n",
    "    log_posterior_unnorm += torch.randn(*log_posterior_unnorm.shape).to(log_lik.device) * noise\n",
    "    log_posterior = log_posterior_unnorm - torch.logsumexp(log_posterior_unnorm, axis=-1).unsqueeze(-1)\n",
    "    post_pr = torch.exp(log_posterior)\n",
    "\n",
    "    loss = 0.0\n",
    "    for m, pred in enumerate(preds):\n",
    "        nll_k = nll_loss_per_sample(pred, data) * post_pr[...,m] \n",
    "        nll_k = nll_k.sum(-1) / data['car_mask'][...,0].sum(-1)\n",
    "        loss += nll_k.sum()\n",
    "\n",
    "    kl_loss = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "    loss += kl_loss(torch.log(modes_pred.unsqueeze(1)), post_pr) \n",
    "    return loss \n",
    "\n",
    "def nonsingular_loss(multi_preds, epsilon=0.01):\n",
    "    loss = 0.\n",
    "    for i, preds in enumerate(multi_preds):\n",
    "        for j, pred in enumerate(preds):\n",
    "            loss = loss + torch.relu(epsilon - pred[...,1:,:].det()).mean()\n",
    "    return loss / (i + j + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:46.691482Z",
     "start_time": "2021-05-05T16:44:45.979241Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets.argoverse_lane_loader import read_pkl_data\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:46.695221Z",
     "start_time": "2021-05-05T16:44:46.693111Z"
    }
   },
   "outputs": [],
   "source": [
    "datapath = '/home/leo/particle/argoverse/argoverse_forecasting/train/lane_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:46.698781Z",
     "start_time": "2021-05-05T16:44:46.696527Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = read_pkl_data(datapath, 2, max_car=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:47.195891Z",
     "start_time": "2021-05-05T16:44:46.700237Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T05:54:56.743436Z",
     "start_time": "2021-05-05T05:54:52.879396Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2741it [00:03, 723.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-99ebbd1f89cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0;34m'vel'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 ['pos_2s', 'vel_2s', 'lane', 'lane_norm'])\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconvert_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/particle/RandomTrafficFluid/datasets/argoverse_lane_loader.py\u001b[0m in \u001b[0;36mread_pkl_data\u001b[0;34m(data_path, batch_size, max_car, shuffle, repeat, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/envs/particle/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/envs/particle/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/envs/particle/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/particle/RandomTrafficFluid/datasets/argoverse_lane_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpkl_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpkl_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;31m# data = {k:v[0] for k, v in data.items()}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mlane_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_lane_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "convert_keys = (['pos' + str(i) for i in range(31)] + \n",
    "                ['vel' + str(i) for i in range(31)] + \n",
    "                ['pos_2s', 'vel_2s', 'lane', 'lane_norm'])\n",
    "for data in tqdm.tqdm(dataset):\n",
    "    for k in convert_keys:\n",
    "        if np.isnan(data[k]).any():\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:48.121558Z",
     "start_time": "2021-05-05T16:44:48.101591Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = len(batch['pos0'])\n",
    "\n",
    "batch_tensor = {}\n",
    "convert_keys = (['pos' + str(i) for i in range(31)] + \n",
    "                ['vel' + str(i) for i in range(31)] + \n",
    "                ['pos_2s', 'vel_2s', 'lane', 'lane_norm'])\n",
    "\n",
    "for k in convert_keys:\n",
    "    batch_tensor[k] = torch.tensor(np.stack(batch[k]), dtype=torch.float32, device=device)\n",
    "\n",
    "for k in ['car_mask', 'lane_mask']:\n",
    "    batch_tensor[k] = torch.tensor(np.stack(batch[k]), dtype=torch.float32, device=device).unsqueeze(-1)\n",
    "\n",
    "for k in ['track_id' + str(i) for i in range(31)] + ['city', 'agent_id', 'scene_idx']:\n",
    "    batch_tensor[k] = np.stack(batch[k])\n",
    "\n",
    "batch_tensor['car_mask'] = batch_tensor['car_mask'].squeeze(-1)\n",
    "batch_tensor['agent_id'] = batch_tensor['agent_id'][:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:49.097674Z",
     "start_time": "2021-05-05T16:44:49.089177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tensor['car_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:49.779738Z",
     "start_time": "2021-05-05T16:44:49.774560Z"
    }
   },
   "outputs": [],
   "source": [
    "# p_enc, v_enc, p, v, map_p, map_feat, car_mask, map_mask\n",
    "inputs = ([\n",
    "    batch_tensor['pos_2s'], batch_tensor['vel_2s'], \n",
    "    batch_tensor['pos0'], batch_tensor['vel0'], \n",
    "    batch_tensor['lane'], batch_tensor['lane_norm'], \n",
    "    batch_tensor['car_mask'], batch_tensor['lane_mask']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:51.357244Z",
     "start_time": "2021-05-05T16:44:50.464264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.2967, device='cuda:0', grad_fn=<MaxBackward1>) tensor(0.4486, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "traj_preds, mode_pred = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T05:39:21.528783Z",
     "start_time": "2021-05-05T05:39:21.510441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.2643e+03,  1.9516e+03],\n",
       "          [-5.7332e-01, -2.6134e+00],\n",
       "          [-9.7433e-01, -7.8999e-01]],\n",
       "\n",
       "         [[ 3.2783e+03,  1.9783e+03],\n",
       "          [-1.5892e-01, -1.7729e-01],\n",
       "          [ 4.2915e-06,  3.8850e-02]],\n",
       "\n",
       "         [[ 3.2376e+03,  1.9290e+03],\n",
       "          [-4.9331e+00, -1.0109e+01],\n",
       "          [-2.5961e+00, -1.7283e+00]],\n",
       "\n",
       "         [[ 3.2768e+03,  1.9761e+03],\n",
       "          [-1.5572e-01, -1.7676e-01],\n",
       "          [-5.9481e-02,  3.0278e-02]],\n",
       "\n",
       "         [[ 3.2186e+03,  1.9395e+03],\n",
       "          [ 8.1726e-01, -1.9085e+00],\n",
       "          [-1.4666e+00,  1.1846e+00]],\n",
       "\n",
       "         [[ 3.2678e+03,  1.9213e+03],\n",
       "          [ 3.9941e+00,  4.2584e+00],\n",
       "          [ 7.6987e-01,  5.9982e-01]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 8.2759e+02,  2.0642e+03],\n",
       "          [ 9.9810e-01,  8.2483e-02],\n",
       "          [ 3.9950e-01, -6.8424e-03]],\n",
       "\n",
       "         [[ 8.2576e+02,  2.0924e+03],\n",
       "          [-4.0253e-01, -7.0157e-01],\n",
       "          [-4.7601e-01, -1.1905e-01]],\n",
       "\n",
       "         [[ 8.4102e+02,  2.0632e+03],\n",
       "          [-6.9536e-01,  2.0729e+00],\n",
       "          [ 7.2931e-02,  7.4620e-01]],\n",
       "\n",
       "         [[ 8.3009e+02,  2.0845e+03],\n",
       "          [-1.5250e-01,  1.4779e+00],\n",
       "          [ 1.1194e-01,  5.5260e-01]],\n",
       "\n",
       "         [[ 8.1900e+02,  2.0948e+03],\n",
       "          [ 3.3461e-01, -1.6301e+00],\n",
       "          [-2.6345e-01, -5.9621e-01]],\n",
       "\n",
       "         [[ 8.4061e+02,  2.0608e+03],\n",
       "          [-6.2024e-01,  2.0638e+00],\n",
       "          [ 1.4444e-01,  6.9078e-01]],\n",
       "\n",
       "         [[ 8.3165e+02,  2.0775e+03],\n",
       "          [-2.3240e+00, -1.1778e-01],\n",
       "          [-8.6406e-01,  1.8988e-01]],\n",
       "\n",
       "         [[ 8.2562e+02,  2.0602e+03],\n",
       "          [ 1.1948e+00, -1.7304e-02],\n",
       "          [ 3.7331e-01, -8.3112e-02]],\n",
       "\n",
       "         [[ 8.2202e+02,  2.0953e+03],\n",
       "          [ 2.5424e-01, -1.5581e+00],\n",
       "          [-2.8689e-01, -4.9952e-01]],\n",
       "\n",
       "         [[ 8.1461e+02,  2.0745e+03],\n",
       "          [ 1.2881e+00, -5.0762e-02],\n",
       "          [ 3.5372e-01, -2.7065e-01]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]]]], device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_preds[0][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:44:55.660509Z",
     "start_time": "2021-05-05T16:44:55.437875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 30, 6]) torch.Size([2, 1, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(20.6208, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll_loss_multimodes(traj_preds, batch_tensor, mode_pred)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:25:02.800948Z",
     "start_time": "2021-05-05T16:25:00.395929Z"
    }
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T05:47:09.498018Z",
     "start_time": "2021-04-28T05:47:09.495581Z"
    }
   },
   "outputs": [],
   "source": [
    "traj_pred0 = traj_preds[0]\n",
    "gt = p_gt['pos1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T06:04:12.716483Z",
     "start_time": "2021-04-28T06:04:12.708429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_loss(traj_pred0[0], gt, car_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T21:35:20.389396Z",
     "start_time": "2021-04-28T21:35:18.361160Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.reset_predict_window(30)\n",
    "    traj_preds_eval, mode_pred_eval = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T21:36:47.403493Z",
     "start_time": "2021-04-28T21:36:47.399397Z"
    }
   },
   "outputs": [],
   "source": [
    "traj_pred_one_mode = traj_preds_eval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T21:49:07.457504Z",
     "start_time": "2021-04-28T21:49:07.451251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pos0', 'pos1', 'pos2', 'pos3', 'pos4', 'pos5', 'pos6', 'pos7', 'pos8', 'pos9', 'pos10', 'vel0', 'vel1', 'vel2', 'vel3', 'vel4', 'vel5', 'vel6', 'vel7', 'vel8', 'vel9', 'vel10', 'pos_2s', 'vel_2s', 'lane', 'lane_norm', 'car_mask', 'lane_mask', 'track_id0', 'track_id1', 'track_id2', 'track_id3', 'track_id4', 'track_id5', 'track_id6', 'track_id7', 'track_id8', 'track_id9', 'track_id10', 'track_id11', 'track_id12', 'track_id13', 'track_id14', 'track_id15', 'track_id16', 'track_id17', 'track_id18', 'track_id19', 'track_id20', 'track_id21', 'track_id22', 'track_id23', 'track_id24', 'track_id25', 'track_id26', 'track_id27', 'track_id28', 'track_id29', 'track_id30', 'city', 'agent_id', 'scene_idx'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tensor.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T21:58:35.454913Z",
     "start_time": "2021-04-28T21:58:35.443972Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_de(traj_pred_one_mode, batch_tensor):\n",
    "    des = []\n",
    "    for t, pred in enumerate(traj_pred_one_mode):\n",
    "        pred_agent, gt_agent = get_agent(pred, batch_tensor['pos'+str(t+1)], \n",
    "                               batch_tensor['track_id0'], batch_tensor['track_id'+str(t+1)], \n",
    "                               batch_tensor['agent_id'])\n",
    "        des.append(torch.norm(pred_agent[...,0,:] - gt_agent, dim=-1))\n",
    "    return torch.stack(des, -1)\n",
    "\n",
    "def get_de_multi_modes(traj_pred, batch_tensor):\n",
    "    des = []\n",
    "    for m, preds in enumerate(traj_pred):\n",
    "        des.append(get_de(preds, batch_tensor))\n",
    "    return torch.stack(des, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T21:58:52.585375Z",
     "start_time": "2021-04-28T21:58:52.522846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 6])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_de_multi_modes(traj_preds_eval, batch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T21:44:46.064577Z",
     "start_time": "2021-04-28T21:44:46.059006Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_agent(pr, gt, pr_id, gt_id, agent_id, device='cpu'):\n",
    "    pr_agent = pr[pr_id == agent_id,:]\n",
    "    gt_agent = gt[gt_id == agent_id,:]\n",
    "    \n",
    "    return pr_agent, gt_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T18:00:41.569539Z",
     "start_time": "2021-04-28T18:00:39.500261Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "p_enc = torch.rand(batch_size, 30, 18, 2).to(device)\n",
    "v_enc = torch.rand(batch_size, 30, 18, 2).to(device)\n",
    "p = torch.rand(batch_size, 30, 2).to(device)\n",
    "v = torch.rand(batch_size, 30, 2).to(device)\n",
    "map_p = torch.rand(batch_size, 650, 2).to(device)\n",
    "map_feat = torch.rand(batch_size, 650, 2).to(device)\n",
    "car_mask = torch.tensor([1.] * 30).to(device)\n",
    "map_mask = torch.tensor([1.] * 650).to(device)\n",
    "\n",
    "p_gt = {'pos{}'.format(i + 1): torch.rand(batch_size, 30, 2).to(device) for i in range(30)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T17:51:24.174318Z",
     "start_time": "2021-04-28T17:51:23.421413Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = (p_enc, v_enc, p, v, map_p, map_feat, car_mask, map_mask)\n",
    "traj_preds, mode_pred = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T04:30:32.470856Z",
     "start_time": "2021-04-28T04:30:29.932446Z"
    }
   },
   "outputs": [],
   "source": [
    "vehicle_encoder = VehicleEncoder().to(device)\n",
    "map_encoder = MapEncoder().to(device)\n",
    "\n",
    "traj_decoder = TrajectoryDecoder(predict_window=30, map_encoder=map_encoder).to(device)\n",
    "mode_decoder = ModeDecoder(modes=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T04:32:51.616768Z",
     "start_time": "2021-04-28T04:32:51.580347Z"
    }
   },
   "outputs": [],
   "source": [
    "vehicle_hidden = model.vehicle_encoder((p_enc, v_enc, p, v, car_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T03:28:29.141513Z",
     "start_time": "2021-04-28T03:28:29.134712Z"
    }
   },
   "outputs": [],
   "source": [
    "encode_map = map_encoder(p, map_p, map_feat, map_mask)\n",
    "feat = torch.cat([vehicle_hidden, encode_map], dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T03:28:30.481349Z",
     "start_time": "2021-04-28T03:28:29.955056Z"
    }
   },
   "outputs": [],
   "source": [
    "traj_pred = traj_decoder(p, feat, map_p, map_feat, car_mask, map_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T03:32:13.645695Z",
     "start_time": "2021-04-28T03:32:13.637341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1376, 0.1893, 0.1734, 0.1731, 0.1294, 0.1972],\n",
       "        [0.1357, 0.1906, 0.1737, 0.1734, 0.1272, 0.1994],\n",
       "        [0.1367, 0.1899, 0.1734, 0.1732, 0.1285, 0.1983],\n",
       "        [0.1365, 0.1900, 0.1736, 0.1732, 0.1284, 0.1983]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_decoder(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T21:16:06.841993Z",
     "start_time": "2021-04-28T21:16:06.832312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1],\n",
       "          [1],\n",
       "          [1]]],\n",
       "\n",
       "\n",
       "        [[[2],\n",
       "          [2],\n",
       "          [2]]],\n",
       "\n",
       "\n",
       "        [[[3],\n",
       "          [3],\n",
       "          [3]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(\n",
    "    [[[1],[1],[1],[2],[2],[2],[3],[3],[3]]]\n",
    ").reshape(3,1,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T06:51:59.850060Z",
     "start_time": "2021-04-29T06:51:59.842464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.8916e+09)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[-3.0457e+07, -2.2553e+07],\n",
    "         [-2.2553e+07, -1.6700e+07]]).det()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
