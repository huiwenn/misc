{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a63a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from termcolor import cprint\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import utils.baseline_utils as baseline_utils\n",
    "#from lstm_train_test_det import *\n",
    "from lstm_train_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb6b40d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70ee8821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agents_train.npy\t       agents_val_rotation.npy\ttest_obs\r\n",
      "agents_train_rotation.npy      agents_val_transi.npy\ttrain\r\n",
      "agents_train_small.npy\t       argoverse-api.git\ttrain_original\r\n",
      "agents_train_small_transi.npy  features\t\t\tval\r\n",
      "agents_train_transi.npy        preprocessing.ipynb\tval_original\r\n",
      "agents_val.npy\t\t       test\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../argoverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79076f43",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('../../argoverse/agents_train_rotation.npy', 'rb') as f:\n",
    "    wholetraj = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1372e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205942, 50, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wholetraj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "662d920d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102971, 50, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conformal_train = wholetraj[:102971]\n",
    "conformal_err = wholetraj[102971:]\n",
    "conformal_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fef34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../argoverse/conformal_train.npy', 'wb') as f:\n",
    "    np.save(f, conformal_train)\n",
    "    \n",
    "with open('../../argoverse/conformal_err.npy', 'wb') as f:\n",
    "    np.save(f, conformal_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cde22775",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5954ad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '../checkpoints/argo_lstm_conformal/LSTM_rollout30.pth.tar'\n",
      "=> loaded checkpoint ../checkpoints/argo_lstm_conformal/LSTM_rollout30.pth.tar (epoch: 193, loss: 4.861854553222656)\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(input_size=2)\n",
    "decoder = DecoderRNN(output_size=2)\n",
    "encoder = nn.DataParallel(encoder)\n",
    "decoder = nn.DataParallel(decoder)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters())\n",
    "\n",
    "model_utils = ModelUtils()\n",
    "\n",
    "model_path = '../checkpoints/argo_lstm_conformal/LSTM_rollout30.pth.tar'\n",
    "epoch, rollout_len, _ = model_utils.load_checkpoint(\n",
    "            model_path, encoder, decoder, encoder_optimizer,\n",
    "            decoder_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a835110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for LSTM Baselines.\"\"\"\n",
    "    def __init__(self, wholetraj, shuffle=True):\n",
    "        normalized = wholetraj\n",
    "\n",
    "        self.input_data = normalized[:, :20, :]\n",
    "        self.output_data = normalized[:, 20:, :]\n",
    "        self.data_size = self.input_data.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "\n",
    "    def __getitem__(self, idx: int\n",
    "                    ) -> Tuple[torch.FloatTensor, Any, Dict[str, np.ndarray]]:\n",
    "        return (\n",
    "            torch.FloatTensor(self.input_data[idx]),\n",
    "            torch.FloatTensor(\n",
    "                self.output_data[idx])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dd2192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils = ModelUtils()\n",
    "\n",
    "val_dataset = LSTMDataset(conformal_err)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=128,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        collate_fn=model_utils.my_collate_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d14be234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f0a02660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [00:34,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "rollout_len = 30\n",
    "all_mse = {}\n",
    "all_de = []\n",
    "for i, (_input, target, helpers) in tqdm(enumerate(val_loader)):\n",
    "\n",
    "    _input = _input.to(device)\n",
    "    target = target.to(device)\n",
    "\n",
    "    # Encoder\n",
    "    batch_size = _input.shape[0]\n",
    "    input_length = _input.shape[1]\n",
    "    output_length = target.shape[1]\n",
    "    input_shape = _input.shape[2]\n",
    "\n",
    "    # Initialize encoder hidden state\n",
    "    encoder_hidden = model_utils.init_hidden(\n",
    "        batch_size,\n",
    "        encoder.module.hidden_size if use_cuda else encoder.hidden_size)\n",
    "\n",
    "\n",
    "    # Encode observed trajectory\n",
    "    for ei in range(input_length):\n",
    "        encoder_input = _input[:, ei, :]\n",
    "        encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "    # Initialize decoder input with last coordinate in encoder\n",
    "    decoder_input = encoder_input\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    output_shape = list(target.shape)\n",
    "    decoder_outputs = torch.zeros(output_shape).to(device)\n",
    "    \n",
    "    mses = torch.zeros(rollout_len).to(device)\n",
    "    de = []\n",
    "\n",
    "    for di in range(rollout_len):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input,\n",
    "                                                 decoder_hidden)\n",
    "        decoder_outputs[:, di, :] = decoder_output\n",
    "        mses = (decoder_output[:, :2]-target[:, di, :2]).pow(2).sum(axis=-1).pow(0.5)\n",
    "        if di in all_mse:\n",
    "            all_mse[di] = np.concatenate((all_mse[di], mses.detach().cpu().numpy()))\n",
    "        else:\n",
    "            all_mse[di] = mses.detach().cpu().numpy()\n",
    "\n",
    "        # Use own predictions as inputs at next step\n",
    "        decoder_input = decoder_output\n",
    "        de.append(torch.sqrt((decoder_output[:, 0] - target[:, di, 0])**2 +\n",
    "                           (decoder_output[:, 1] - target[:, di, 1])**2).detach().cpu().numpy())\n",
    "    \n",
    "    all_de.append(de)\n",
    "    \n",
    "    if i>60:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d5db00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ninetyquant = []\n",
    "for i in range(30):\n",
    "    q = np.quantile(all_mse[i], 0.9)\n",
    "    ninetyquant.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "acb0aa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9199341535568237,\n",
       " 0.9753382205963135,\n",
       " 1.0859079957008362,\n",
       " 1.2161036133766174,\n",
       " 1.3877891302108765,\n",
       " 1.5531651377677917,\n",
       " 1.752310037612915,\n",
       " 2.0071715116500854,\n",
       " 2.247078537940979,\n",
       " 2.494024634361267,\n",
       " 2.793949842453003,\n",
       " 3.1226292848587036,\n",
       " 3.4556496143341064,\n",
       " 3.8185853958129883,\n",
       " 4.143992185592651,\n",
       " 4.531986236572266,\n",
       " 4.937242269515991,\n",
       " 5.381857633590698,\n",
       " 5.768104076385498,\n",
       " 6.165144205093384,\n",
       " 6.541731119155884,\n",
       " 6.962288856506348,\n",
       " 7.428401231765747,\n",
       " 7.888824701309204,\n",
       " 8.417593002319336,\n",
       " 8.935048580169678,\n",
       " 9.438450336456299,\n",
       " 9.91438627243042,\n",
       " 10.462123394012451,\n",
       " 10.978078842163086]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ninetyquant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9d4b9911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.15947"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(de).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f99b43b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../argoverse/agents_val.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../argoverse/agents_val.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fc1fffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "with open('../../argoverse/agents_val_rotation.npy', 'rb') as f:\n",
    "    test_datase = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f52460d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = LSTMDataset(test_datase)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=128,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        collate_fn=model_utils.my_collate_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6b081030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:23,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "rollout_len = 30\n",
    "all_coverage = {}\n",
    "de_test = []\n",
    "mrses = []\n",
    "for i, (_input, target, helpers) in tqdm(enumerate(test_loader)):\n",
    "\n",
    "    _input = _input.to(device)\n",
    "    target = target.to(device)\n",
    "\n",
    "    # Encoder\n",
    "    batch_size = _input.shape[0]\n",
    "    input_length = _input.shape[1]\n",
    "    output_length = target.shape[1]\n",
    "    input_shape = _input.shape[2]\n",
    "\n",
    "    # Initialize encoder hidden state\n",
    "    encoder_hidden = model_utils.init_hidden(\n",
    "        batch_size,\n",
    "        encoder.module.hidden_size if use_cuda else encoder.hidden_size)\n",
    "\n",
    "\n",
    "    # Encode observed trajectory\n",
    "    for ei in range(input_length):\n",
    "        \n",
    "        encoder_input = _input[:, ei, :]\n",
    "        encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "    # Initialize decoder input with last coordinate in encoder\n",
    "    decoder_input = encoder_input\n",
    "    decoder_hidden = encoder_hidden\n",
    "    output_shape = list(target.shape)\n",
    "    decoder_outputs = torch.zeros(output_shape).to(device)\n",
    "    \n",
    "    mses = torch.zeros(rollout_len).to(device)\n",
    "\n",
    "    for di in range(rollout_len):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "        decoder_outputs[:, di, :] = decoder_output\n",
    "        mses = (decoder_output[:, :2]-target[:, di, :2]).pow(2).sum(axis=-1).pow(0.5)\n",
    "        cover = mses < ninetyquant[di]\n",
    "        \n",
    "        second_part = 1/0.1 * np.pi * (mses.cpu().detach().numpy()**2 - ninetyquant[di]**2) \n",
    "        condition = np.where(second_part<0, 0, second_part)\n",
    "        mrs = np.pi*ninetyquant[di] ** 2 + condition \n",
    "        mrses.append(mrs)\n",
    "        if di in all_coverage:\n",
    "            all_coverage[di] = np.concatenate((all_coverage[di], cover.detach().cpu().numpy()))\n",
    "        else:\n",
    "            all_coverage[di] = cover.detach().cpu().numpy()\n",
    "\n",
    "        # Use own predictions as inputs at next step\n",
    "        decoder_input = decoder_output\n",
    "        de_test.append(torch.sqrt((decoder_output[:, 0] - target[:, di, 0])**2 +\n",
    "                           (decoder_output[:, 1] - target[:, di, 1])**2).detach().cpu().numpy())\n",
    "    if i > 40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c444d97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211.90213"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mrses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "94a9fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrs():\n",
    "    second_part = 1/0.1 * np.pi * (mses.pow(2) - ninetyquant[di].pow(2)) \n",
    "    condition = np.where(second_part<0, 0, second_part)\n",
    "    mrs = np.pi*ninetyquant[di].pow(2) + condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e706540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 309 it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "580e451c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9240, 128)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(de_test[:-30]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "58aeecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_array = np.array(de_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "26aed40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [h.shape for h in de_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b5891cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(128,): 9240, (48,): 30})"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "522623b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_de = np.array(de_test[:-30]).reshape((308,30,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "17bf28f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6787267"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fde = np.mean(new_de[:,29,:])\n",
    "fde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "28f74700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.159612"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.concatenate(de_test).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569447d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.concatenate(de_test).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ffcf0963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006384272395622"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_coverage[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7696f5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.926682205107418"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_coverage[14].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "43e2b426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9276702472638833"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_coverage[29].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbe3ba29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 14 01:08:37 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 27%   44C    P2    61W / 250W |   6363MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 22%   28C    P8     2W / 250W |   1258MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 22%   23C    P8    10W / 250W |   1388MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 23%   40C    P2    62W / 250W |   3019MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 37%   63C    P2   136W / 250W |   3263MiB / 11019MiB |     89%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 32%   43C    P8     9W / 250W |   1324MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 31%   42C    P8    21W / 250W |   1324MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:B2:00.0 Off |                  N/A |\n",
      "| 29%   40C    P8    21W / 250W |   1324MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3528      C   ...da3/envs/pecco/bin/python     1113MiB |\n",
      "|    0   N/A  N/A     54445      C   python                           2235MiB |\n",
      "|    0   N/A  N/A     79228      C   python                           1507MiB |\n",
      "|    1   N/A  N/A     35544      C   python                           1255MiB |\n",
      "|    2   N/A  N/A      3528      C   ...da3/envs/pecco/bin/python     1385MiB |\n",
      "|    3   N/A  N/A     69265      C   python                           1507MiB |\n",
      "|    4   N/A  N/A      3411      C   python                           4457MiB |\n",
      "|    4   N/A  N/A     43240      C   python                           1499MiB |\n",
      "|    5   N/A  N/A      3411      C   python                           1321MiB |\n",
      "|    6   N/A  N/A      3411      C   python                           1321MiB |\n",
      "|    7   N/A  N/A      3411      C   python                           1321MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9a30c",
   "metadata": {},
   "source": [
    "# conformal ecco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "d4c9d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "sys.path.append('.')\n",
    "from collections import namedtuple\n",
    "import time\n",
    "import pickle\n",
    "import argparse\n",
    "from argoverse.map_representation.map_api import ArgoverseMap\n",
    "from datasets.argoverse_loader_old import read_pkl_data\n",
    "from train_utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "f5768c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.rho_reg_ECCO_original import ECCONetwork\n",
    "\"\"\"Returns an instance of the network for training and evaluation\"\"\"\n",
    "model = ECCONetwork(radius_scale = 40, \n",
    "                        layer_channels = [8, 16, 8, 8, 1], \n",
    "                        encoder_hidden_size=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "c74c551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ../conformal-ecco-new\n"
     ]
    }
   ],
   "source": [
    "load_model_path = '../conformal-ecco-new'\n",
    "\n",
    "print('loading model from ' + load_model_path)\n",
    "model = torch.load(load_model_path + '.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "16cbd964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibrate  train  val\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../../argoverse/conformal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "99bcb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_path = '../../argoverse/conformal/calibrate'\n",
    "cal_dataset = read_pkl_data(val_path, batch_size=8, shuffle=False, repeat=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "d1e5be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = '../../argoverse/conformal/val'\n",
    "val_dataset = read_pkl_data(val_path, batch_size=8, shuffle=False, repeat=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "1095264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "20325f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 {'ADE': 2.0078743, 'ADE_std': 1.9154725, 'DE@1s': 1.1720881, 'DE@1s_std': 1.2563577, 'DE@2s': 2.7079055, 'DE@2s_std': 2.710586, 'DE@3s': 4.561687, 'DE@3s_std': 4.3232603}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    prediction_gt = {}\n",
    "    losses = []\n",
    "    all_mse = []\n",
    "\n",
    "    val_iter = iter(cal_dataset)\n",
    "\n",
    "    for i, sample in enumerate(cal_dataset):\n",
    "        pred = []\n",
    "        gt = []\n",
    "\n",
    "        if count % 1 == 0:\n",
    "            print('{}'.format(count + 1), end=' ', flush=True)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        data = {}\n",
    "        convert_keys = (['pos' + str(i) for i in range(31)] + \n",
    "                        ['vel' + str(i) for i in range(31)] + \n",
    "                        ['pos_2s', 'vel_2s', 'lane', 'lane_norm'])\n",
    "\n",
    "        for k in convert_keys:\n",
    "            data[k] = torch.tensor(np.stack(sample[k])[...,:2], dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "        for k in ['track_id' + str(i) for i in range(31)] + ['city', 'agent_id', 'scene_idx']:\n",
    "            data[k] = np.stack(sample[k])\n",
    "\n",
    "        for k in ['car_mask', 'lane_mask']:\n",
    "            data[k] = torch.tensor(np.stack(sample[k]), dtype=torch.float32, device=device).unsqueeze(-1)\n",
    "\n",
    "        scenes = data['scene_idx'].tolist()\n",
    "        data['agent_id'] = data['agent_id'][:,np.newaxis]\n",
    "\n",
    "        data['car_mask'] = data['car_mask'].squeeze(-1)\n",
    "        accel = torch.zeros(1, 1, 2).to(device)\n",
    "        data['accel'] = accel\n",
    "\n",
    "        lane = data['lane']\n",
    "        lane_normals = data['lane_norm']\n",
    "        agent_id = data['agent_id']\n",
    "        city = data['city']\n",
    "\n",
    "        inputs = ([\n",
    "            data['pos_2s'], data['vel_2s'], \n",
    "            data['pos0'], data['vel0'], \n",
    "            data['accel'], None,\n",
    "            data['lane'], data['lane_norm'], \n",
    "            data['car_mask'], data['lane_mask']\n",
    "        ])\n",
    "\n",
    "        pr_pos1, pr_vel1, states = model(inputs)\n",
    "        gt_pos1 = data['pos1']\n",
    "\n",
    "        l = 0.5 * loss_fn(pr_pos1, gt_pos1, \n",
    "                          torch.sum(data['car_mask'], dim = -2) - 1, data['car_mask'].squeeze(-1))\n",
    "\n",
    "        pr_agent, gt_agent = get_agent_ecco(pr_pos1, data['pos1'],\n",
    "                                       data['track_id0'], \n",
    "                                       data['track_id1'], \n",
    "                                       agent_id, device)\n",
    "        pred.append(pr_agent.unsqueeze(1).detach().cpu())\n",
    "        gt.append(gt_agent.unsqueeze(1).detach().cpu())\n",
    "        del pr_agent, gt_agent\n",
    "        clean_cache(device)\n",
    "\n",
    "        pos0 = data['pos0']\n",
    "        vel0 = data['vel0']\n",
    "        for i in range(29):\n",
    "            pos_enc = torch.unsqueeze(pos0, 2)\n",
    "            vel_enc = torch.unsqueeze(vel0, 2)\n",
    "            inputs = (pos_enc, vel_enc, pr_pos1, pr_vel1, data['accel'], None, \n",
    "                      data['lane'], data['lane_norm'], data['car_mask'], data['lane_mask'])\n",
    "            pos0, vel0 = pr_pos1, pr_vel1\n",
    "            pr_pos1, pr_vel1, states = model(inputs, states)\n",
    "            clean_cache(device)\n",
    "\n",
    "            if i < train_window - 1:\n",
    "                gt_pos1 = data['pos'+str(i+2)]\n",
    "                l += 0.5 * loss_fn(pr_pos1, gt_pos1,\n",
    "                                   torch.sum(data['car_mask'], dim = -2) - 1, data['car_mask'].squeeze(-1))\n",
    "\n",
    "            pr_agent, gt_agent = get_agent_ecco(pr_pos1, data['pos'+str(i+2)],\n",
    "                                           data['track_id0'], \n",
    "                                           data['track_id'+str(i+2)], \n",
    "                                           agent_id, device)\n",
    "\n",
    "            pred.append(pr_agent.unsqueeze(1).detach().cpu())\n",
    "            gt.append(gt_agent.unsqueeze(1).detach().cpu())\n",
    "\n",
    "            clean_cache(device)\n",
    "\n",
    "        losses.append(l)\n",
    "\n",
    "        predict_result = (torch.cat(pred, axis=1), torch.cat(gt, axis=1))\n",
    "        for idx, scene_id in enumerate(scenes):\n",
    "            prediction_gt[scene_id] = (predict_result[0][idx], predict_result[1][idx])\n",
    "        \n",
    "        if count > 800:\n",
    "            break\n",
    "\n",
    "    try:\n",
    "        total_loss = torch.sum(torch.stack(losses),axis=0) / max_iter\n",
    "    except:\n",
    "        total_loss = 0\n",
    "\n",
    "    result = {}\n",
    "    de = {}\n",
    "    \n",
    "    for k, v in prediction_gt.items():\n",
    "        mse = (v[0][:,:]-v[1][:,:]).pow(2).sum(axis=-1).pow(0.5)\n",
    "        all_mse.append(mse.detach().numpy())\n",
    "        de[k] = torch.sqrt((v[0][:,0] - v[1][:,0])**2 + \n",
    "                        (v[0][:,1] - v[1][:,1])**2)\n",
    "\n",
    "    ade = []\n",
    "    de1s = []\n",
    "    de2s = []\n",
    "    de3s = []\n",
    "    for k, v in de.items():\n",
    "        ade.append(np.mean(v.numpy()))\n",
    "        de1s.append(v.numpy()[10])\n",
    "        de2s.append(v.numpy()[20])\n",
    "        de3s.append(v.numpy()[-1])\n",
    "\n",
    "    result['ADE'] = np.mean(ade)\n",
    "    result['ADE_std'] = np.std(ade)\n",
    "    result['DE@1s'] = np.mean(de1s)\n",
    "    result['DE@1s_std'] = np.std(de1s)\n",
    "    result['DE@2s'] = np.mean(de2s)\n",
    "    result['DE@2s_std'] = np.std(de2s)\n",
    "    result['DE@3s'] = np.mean(de3s)\n",
    "    result['DE@3s_std'] = np.std(de3s)\n",
    "\n",
    "    print(result)\n",
    "    print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567e194e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "7fac4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_ecco(pr, gt, pr_id, gt_id, agent_id, device='cpu'):\n",
    "        \n",
    "    pr_agent = pr[pr_id == agent_id,:]\n",
    "    gt_agent = gt[gt_id == agent_id,:]\n",
    "    \n",
    "    return pr_agent, gt_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "3b743b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mse = [l.detach().numpy() for l in all_mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "963bdb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1879, 30)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mse = np.array(all_mse)\n",
    "all_mse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "2b9eef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ninetyquant = []\n",
    "for i in range(30):\n",
    "    q = np.quantile(all_mse[:,i], 0.9)\n",
    "    ninetyquant.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "e09620e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5263745784759523,\n",
       " 0.7044272184371948,\n",
       " 0.8153408527374268,\n",
       " 0.9904256820678712,\n",
       " 1.1850415706634523,\n",
       " 1.3769285678863525,\n",
       " 1.5819029569625862,\n",
       " 1.6921488285064696,\n",
       " 1.9486913681030276,\n",
       " 2.225640773773194,\n",
       " 2.4322388648986824,\n",
       " 2.6510236263275155,\n",
       " 2.945130205154419,\n",
       " 3.2434028625488285,\n",
       " 3.5610769271850584,\n",
       " 3.8270337104797365,\n",
       " 4.163390064239502,\n",
       " 4.436709499359132,\n",
       " 4.734423065185547,\n",
       " 5.203984355926514,\n",
       " 5.651400947570801,\n",
       " 6.060585594177247,\n",
       " 6.366055202484132,\n",
       " 6.839110851287845,\n",
       " 7.364124011993409,\n",
       " 7.811906909942628,\n",
       " 8.197876548767091,\n",
       " 8.637243843078615,\n",
       " 9.115517807006837,\n",
       " 9.614289665222168]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ninetyquant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "642f893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 {'ADE': 2.0084646, 'ADE_std': 1.9147258, 'DE@1s': 1.1727345, 'DE@1s_std': 1.2566749, 'DE@2s': 2.7086236, 'DE@2s_std': 2.7090895, 'DE@3s': 4.5598664, 'DE@3s_std': 4.3220024}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    prediction_gt = {}\n",
    "    losses = []\n",
    "    all_mse = []\n",
    "    mrses = []\n",
    "    all_coverage = []\n",
    "    val_iter = iter(val_dataset)\n",
    "\n",
    "    for i, sample in enumerate(val_dataset):\n",
    "        pred = []\n",
    "        gt = []\n",
    "\n",
    "        if count % 1 == 0:\n",
    "            print('{}'.format(count + 1), end=' ', flush=True)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        data = {}\n",
    "        convert_keys = (['pos' + str(i) for i in range(31)] + \n",
    "                        ['vel' + str(i) for i in range(31)] + \n",
    "                        ['pos_2s', 'vel_2s', 'lane', 'lane_norm'])\n",
    "\n",
    "        for k in convert_keys:\n",
    "            data[k] = torch.tensor(np.stack(sample[k])[...,:2], dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "        for k in ['track_id' + str(i) for i in range(31)] + ['city', 'agent_id', 'scene_idx']:\n",
    "            data[k] = np.stack(sample[k])\n",
    "\n",
    "        for k in ['car_mask', 'lane_mask']:\n",
    "            data[k] = torch.tensor(np.stack(sample[k]), dtype=torch.float32, device=device).unsqueeze(-1)\n",
    "\n",
    "        scenes = data['scene_idx'].tolist()\n",
    "        data['agent_id'] = data['agent_id'][:,np.newaxis]\n",
    "\n",
    "        data['car_mask'] = data['car_mask'].squeeze(-1)\n",
    "        accel = torch.zeros(1, 1, 2).to(device)\n",
    "        data['accel'] = accel\n",
    "\n",
    "        lane = data['lane']\n",
    "        lane_normals = data['lane_norm']\n",
    "        agent_id = data['agent_id']\n",
    "        city = data['city']\n",
    "\n",
    "        inputs = ([\n",
    "            data['pos_2s'], data['vel_2s'], \n",
    "            data['pos0'], data['vel0'], \n",
    "            data['accel'], None,\n",
    "            data['lane'], data['lane_norm'], \n",
    "            data['car_mask'], data['lane_mask']\n",
    "        ])\n",
    "\n",
    "        pr_pos1, pr_vel1, states = model(inputs)\n",
    "        gt_pos1 = data['pos1']\n",
    "\n",
    "        l = 0.5 * loss_fn(pr_pos1, gt_pos1, \n",
    "                          torch.sum(data['car_mask'], dim = -2) - 1, data['car_mask'].squeeze(-1))\n",
    "\n",
    "        pr_agent, gt_agent = get_agent_ecco(pr_pos1, data['pos1'],\n",
    "                                       data['track_id0'], \n",
    "                                       data['track_id1'], \n",
    "                                       agent_id, device)\n",
    "        pred.append(pr_agent.unsqueeze(1).detach().cpu())\n",
    "        gt.append(gt_agent.unsqueeze(1).detach().cpu())\n",
    "        del pr_agent, gt_agent\n",
    "        clean_cache(device)\n",
    "\n",
    "        pos0 = data['pos0']\n",
    "        vel0 = data['vel0']\n",
    "        for i in range(29):\n",
    "            pos_enc = torch.unsqueeze(pos0, 2)\n",
    "            vel_enc = torch.unsqueeze(vel0, 2)\n",
    "            inputs = (pos_enc, vel_enc, pr_pos1, pr_vel1, data['accel'], None, \n",
    "                      data['lane'], data['lane_norm'], data['car_mask'], data['lane_mask'])\n",
    "            pos0, vel0 = pr_pos1, pr_vel1\n",
    "            pr_pos1, pr_vel1, states = model(inputs, states)\n",
    "            clean_cache(device)\n",
    "\n",
    "            if i < train_window - 1:\n",
    "                gt_pos1 = data['pos'+str(i+2)]\n",
    "                l += 0.5 * loss_fn(pr_pos1, gt_pos1,\n",
    "                                   torch.sum(data['car_mask'], dim = -2) - 1, data['car_mask'].squeeze(-1))\n",
    "\n",
    "            pr_agent, gt_agent = get_agent_ecco(pr_pos1, data['pos'+str(i+2)],\n",
    "                                           data['track_id0'], \n",
    "                                           data['track_id'+str(i+2)], \n",
    "                                           agent_id, device)\n",
    "\n",
    "            pred.append(pr_agent.unsqueeze(1).detach().cpu())\n",
    "            gt.append(gt_agent.unsqueeze(1).detach().cpu())\n",
    "\n",
    "            clean_cache(device)\n",
    "\n",
    "        losses.append(l)\n",
    "\n",
    "        predict_result = (torch.cat(pred, axis=1), torch.cat(gt, axis=1))\n",
    "        for idx, scene_id in enumerate(scenes):\n",
    "            prediction_gt[scene_id] = (predict_result[0][idx], predict_result[1][idx])\n",
    "        \n",
    "    try:\n",
    "        total_loss = torch.sum(torch.stack(losses),axis=0) / max_iter\n",
    "    except:\n",
    "        total_loss = 0\n",
    "\n",
    "    result = {}\n",
    "    de = {}\n",
    "    \n",
    "    for k, v in prediction_gt.items():\n",
    "        mse = (v[0][:,:]-v[1][:,:]).pow(2).sum(axis=-1).pow(0.5).cpu().detach().numpy()\n",
    "        all_mse.append(mse)\n",
    "        \n",
    "        cover = mse < ninetyquant\n",
    "        \n",
    "        second_part = 1/0.1 * np.pi * (np.power(mse,2) - np.power(ninetyquant,2)) \n",
    "        condition = np.where(second_part<0, 0, second_part)\n",
    "        mrs = np.pi*np.power(ninetyquant,2) + condition \n",
    "        mrses.append(mrs)\n",
    "        all_coverage.append(cover)\n",
    "\n",
    "        \n",
    "        de[k] = torch.sqrt((v[0][:,0] - v[1][:,0])**2 + \n",
    "                        (v[0][:,1] - v[1][:,1])**2)\n",
    "\n",
    "    ade = []\n",
    "    de1s = []\n",
    "    de2s = []\n",
    "    de3s = []\n",
    "    for k, v in de.items():\n",
    "        ade.append(np.mean(v.numpy()))\n",
    "        de1s.append(v.numpy()[10])\n",
    "        de2s.append(v.numpy()[20])\n",
    "        de3s.append(v.numpy()[-1])\n",
    "\n",
    "    result['ADE'] = np.mean(ade)\n",
    "    result['ADE_std'] = np.std(ade)\n",
    "    result['DE@1s'] = np.mean(de1s)\n",
    "    result['DE@1s_std'] = np.std(de1s)\n",
    "    result['DE@2s'] = np.mean(de2s)\n",
    "    result['DE@2s_std'] = np.std(de2s)\n",
    "    result['DE@3s'] = np.mean(de3s)\n",
    "    result['DE@3s_std'] = np.std(de3s)\n",
    "\n",
    "    print(result)\n",
    "    print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "5e5ded13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1871, 30)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_coverage).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "ec8c5b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9005879208979155"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_coverage)[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "51949ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.900053447354356"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_coverage)[:,9].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "ef1bcb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.900053447354356"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_coverage)[:,19].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "e029a13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.900053447354356"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_coverage)[:,29].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "75cd77aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220.9237621733659"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(mrses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "9a704d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 8, 3, 8, 2])\n",
      "torch.Size([19, 8])\n",
      "torch.Size([1, 8, 3, 8, 2])\n",
      "torch.Size([1, 8])\n",
      "torch.Size([19, 8, 8])\n",
      "torch.Size([24, 16, 3, 8, 8])\n",
      "torch.Size([24, 16, 8])\n",
      "torch.Size([16, 8, 3, 8, 8])\n",
      "torch.Size([16, 8, 8])\n",
      "torch.Size([8, 8, 3, 8, 8])\n",
      "torch.Size([8, 8, 8])\n",
      "torch.Size([8, 1, 3, 2, 8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([24, 16, 8])\n",
      "torch.Size([16, 8, 8])\n",
      "torch.Size([8, 8, 8])\n",
      "torch.Size([8, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "68bc8c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129320"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "9677bf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129320"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_total_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pecco",
   "language": "python",
   "name": "pecco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
