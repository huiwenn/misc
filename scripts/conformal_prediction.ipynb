{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06b0210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from termcolor import cprint\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import utils.baseline_utils as baseline_utils\n",
    "#from lstm_train_test_det import *\n",
    "from lstm_train_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1de3a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9145a63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agents_train.npy\t       agents_val_rotation.npy\ttest_obs\r\n",
      "agents_train_rotation.npy      agents_val_transi.npy\ttrain\r\n",
      "agents_train_small.npy\t       argoverse-api.git\ttrain_original\r\n",
      "agents_train_small_transi.npy  features\t\t\tval\r\n",
      "agents_train_transi.npy        preprocessing.ipynb\tval_original\r\n",
      "agents_val.npy\t\t       test\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../argoverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c4bb5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('../../argoverse/agents_train_rotation.npy', 'rb') as f:\n",
    "    wholetraj = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "598206aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205942, 50, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wholetraj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc59eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102971, 50, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conformal_train = wholetraj[:102971]\n",
    "conformal_err = wholetraj[102971:]\n",
    "conformal_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bca07a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../argoverse/conformal_train.npy', 'wb') as f:\n",
    "    np.save(f, conformal_train)\n",
    "    \n",
    "with open('../../argoverse/conformal_err.npy', 'wb') as f:\n",
    "    np.save(f, conformal_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6889c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e36143bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '../checkpoints/argo_lstm_conformal/LSTM_rollout30.pth.tar'\n",
      "=> loaded checkpoint ../checkpoints/argo_lstm_conformal/LSTM_rollout30.pth.tar (epoch: 193, loss: 4.861854553222656)\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(input_size=2)\n",
    "decoder = DecoderRNN(output_size=2)\n",
    "encoder = nn.DataParallel(encoder)\n",
    "decoder = nn.DataParallel(decoder)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters())\n",
    "\n",
    "model_utils = ModelUtils()\n",
    "\n",
    "model_path = '../checkpoints/argo_lstm_conformal/LSTM_rollout30.pth.tar'\n",
    "epoch, rollout_len, _ = model_utils.load_checkpoint(\n",
    "            model_path, encoder, decoder, encoder_optimizer,\n",
    "            decoder_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "983ca064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for LSTM Baselines.\"\"\"\n",
    "    def __init__(self, wholetraj, shuffle=True):\n",
    "        normalized = wholetraj\n",
    "\n",
    "        self.input_data = normalized[:, :20, :]\n",
    "        self.output_data = normalized[:, 20:, :]\n",
    "        self.data_size = self.input_data.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "\n",
    "    def __getitem__(self, idx: int\n",
    "                    ) -> Tuple[torch.FloatTensor, Any, Dict[str, np.ndarray]]:\n",
    "        return (\n",
    "            torch.FloatTensor(self.input_data[idx]),\n",
    "            torch.FloatTensor(\n",
    "                self.output_data[idx])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc9163ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils = ModelUtils()\n",
    "\n",
    "val_dataset = LSTMDataset(conformal_err)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=128,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        collate_fn=model_utils.my_collate_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18e1a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "49874ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [00:34,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "rollout_len = 30\n",
    "all_mse = {}\n",
    "all_de = []\n",
    "for i, (_input, target, helpers) in tqdm(enumerate(val_loader)):\n",
    "\n",
    "    _input = _input.to(device)\n",
    "    target = target.to(device)\n",
    "\n",
    "    # Encoder\n",
    "    batch_size = _input.shape[0]\n",
    "    input_length = _input.shape[1]\n",
    "    output_length = target.shape[1]\n",
    "    input_shape = _input.shape[2]\n",
    "\n",
    "    # Initialize encoder hidden state\n",
    "    encoder_hidden = model_utils.init_hidden(\n",
    "        batch_size,\n",
    "        encoder.module.hidden_size if use_cuda else encoder.hidden_size)\n",
    "\n",
    "\n",
    "    # Encode observed trajectory\n",
    "    for ei in range(input_length):\n",
    "        encoder_input = _input[:, ei, :]\n",
    "        encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "    # Initialize decoder input with last coordinate in encoder\n",
    "    decoder_input = encoder_input\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    output_shape = list(target.shape)\n",
    "    decoder_outputs = torch.zeros(output_shape).to(device)\n",
    "    \n",
    "    mses = torch.zeros(rollout_len).to(device)\n",
    "    de = []\n",
    "\n",
    "    for di in range(rollout_len):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input,\n",
    "                                                 decoder_hidden)\n",
    "        decoder_outputs[:, di, :] = decoder_output\n",
    "        mses = (decoder_output[:, :2]-target[:, di, :2]).pow(2).sum(axis=-1).pow(0.5)\n",
    "        if di in all_mse:\n",
    "            all_mse[di] = np.concatenate((all_mse[di], mses.detach().cpu().numpy()))\n",
    "        else:\n",
    "            all_mse[di] = mses.detach().cpu().numpy()\n",
    "\n",
    "        # Use own predictions as inputs at next step\n",
    "        decoder_input = decoder_output\n",
    "        de.append(torch.sqrt((decoder_output[:, 0] - target[:, di, 0])**2 +\n",
    "                           (decoder_output[:, 1] - target[:, di, 1])**2).detach().cpu().numpy())\n",
    "    \n",
    "    all_de.append(de)\n",
    "    \n",
    "    if i>60:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6f08fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ninetyquant = []\n",
    "for i in range(30):\n",
    "    q = np.quantile(all_mse[i], 0.9)\n",
    "    ninetyquant.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "61743d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9199341535568237,\n",
       " 0.9753382205963135,\n",
       " 1.0859079957008362,\n",
       " 1.2161036133766174,\n",
       " 1.3877891302108765,\n",
       " 1.5531651377677917,\n",
       " 1.752310037612915,\n",
       " 2.0071715116500854,\n",
       " 2.247078537940979,\n",
       " 2.494024634361267,\n",
       " 2.793949842453003,\n",
       " 3.1226292848587036,\n",
       " 3.4556496143341064,\n",
       " 3.8185853958129883,\n",
       " 4.143992185592651,\n",
       " 4.531986236572266,\n",
       " 4.937242269515991,\n",
       " 5.381857633590698,\n",
       " 5.768104076385498,\n",
       " 6.165144205093384,\n",
       " 6.541731119155884,\n",
       " 6.962288856506348,\n",
       " 7.428401231765747,\n",
       " 7.888824701309204,\n",
       " 8.417593002319336,\n",
       " 8.935048580169678,\n",
       " 9.438450336456299,\n",
       " 9.91438627243042,\n",
       " 10.462123394012451,\n",
       " 10.978078842163086]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ninetyquant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f53af64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.15947"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(de).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bdf017a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../argoverse/agents_val.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../argoverse/agents_val.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4e93686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "with open('../../argoverse/agents_val_rotation.npy', 'rb') as f:\n",
    "    test_datase = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aff0ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = LSTMDataset(test_datase)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=128,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        collate_fn=model_utils.my_collate_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bac4ebe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:23,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "rollout_len = 30\n",
    "all_coverage = {}\n",
    "de_test = []\n",
    "mrses = []\n",
    "for i, (_input, target, helpers) in tqdm(enumerate(test_loader)):\n",
    "\n",
    "    _input = _input.to(device)\n",
    "    target = target.to(device)\n",
    "\n",
    "    # Encoder\n",
    "    batch_size = _input.shape[0]\n",
    "    input_length = _input.shape[1]\n",
    "    output_length = target.shape[1]\n",
    "    input_shape = _input.shape[2]\n",
    "\n",
    "    # Initialize encoder hidden state\n",
    "    encoder_hidden = model_utils.init_hidden(\n",
    "        batch_size,\n",
    "        encoder.module.hidden_size if use_cuda else encoder.hidden_size)\n",
    "\n",
    "\n",
    "    # Encode observed trajectory\n",
    "    for ei in range(input_length):\n",
    "        \n",
    "        encoder_input = _input[:, ei, :]\n",
    "        encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "    # Initialize decoder input with last coordinate in encoder\n",
    "    decoder_input = encoder_input\n",
    "    decoder_hidden = encoder_hidden\n",
    "    output_shape = list(target.shape)\n",
    "    decoder_outputs = torch.zeros(output_shape).to(device)\n",
    "    \n",
    "    mses = torch.zeros(rollout_len).to(device)\n",
    "\n",
    "    for di in range(rollout_len):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "        decoder_outputs[:, di, :] = decoder_output\n",
    "        mses = (decoder_output[:, :2]-target[:, di, :2]).pow(2).sum(axis=-1).pow(0.5)\n",
    "        cover = mses < ninetyquant[di]\n",
    "        \n",
    "        second_part = 1/0.1 * np.pi * (mses.cpu().detach().numpy()**2 - ninetyquant[di]**2) \n",
    "        condition = np.where(second_part<0, 0, second_part)\n",
    "        mrs = np.pi*ninetyquant[di] ** 2 + condition \n",
    "        mrses.append(mrs)\n",
    "        if di in all_coverage:\n",
    "            all_coverage[di] = np.concatenate((all_coverage[di], cover.detach().cpu().numpy()))\n",
    "        else:\n",
    "            all_coverage[di] = cover.detach().cpu().numpy()\n",
    "\n",
    "        # Use own predictions as inputs at next step\n",
    "        decoder_input = decoder_output\n",
    "        de_test.append(torch.sqrt((decoder_output[:, 0] - target[:, di, 0])**2 +\n",
    "                           (decoder_output[:, 1] - target[:, di, 1])**2).detach().cpu().numpy())\n",
    "    if i > 40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1a26cfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211.90213"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mrses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e9ad4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  torch.Tensor(1,40,1).random_(0, 2).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fe896f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0]]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9f75b3f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (2) must match the existing size (40) at non-singleton dimension 2.  Target sizes: [1, 40, 2, 2].  Tensor sizes: [1, 40, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_59065/319124080.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (2) must match the existing size (40) at non-singleton dimension 2.  Target sizes: [1, 40, 2, 2].  Tensor sizes: [1, 40, 1]"
     ]
    }
   ],
   "source": [
    "a.expand((1,40,4)).reshape(1,40,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec0bf0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89003bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrs():\n",
    "    second_part = 1/0.1 * np.pi * (mses.pow(2) - ninetyquant[di].pow(2)) \n",
    "    condition = np.where(second_part<0, 0, second_part)\n",
    "    mrs = np.pi*ninetyquant[di].pow(2) + condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2caf652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 309 it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2ba8cd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9240, 128)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(de_test[:-30]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4e262f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_array = np.array(de_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f64a78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [h.shape for h in de_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a96c7144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(128,): 9240, (48,): 30})"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "cd182005",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_de = np.array(de_test[:-30]).reshape((308,30,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b9db23b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6787267"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fde = np.mean(new_de[:,29,:])\n",
    "fde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "20e85ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.159612"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.concatenate(de_test).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d333558",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.concatenate(de_test).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7369a92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006384272395622"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_coverage[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c54b1e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.926682205107418"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_coverage[14].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9c398e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9276702472638833"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_coverage[29].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "413f2e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 14 01:08:37 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 27%   44C    P2    61W / 250W |   6363MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 22%   28C    P8     2W / 250W |   1258MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 22%   23C    P8    10W / 250W |   1388MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 23%   40C    P2    62W / 250W |   3019MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 37%   63C    P2   136W / 250W |   3263MiB / 11019MiB |     89%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 32%   43C    P8     9W / 250W |   1324MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 31%   42C    P8    21W / 250W |   1324MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:B2:00.0 Off |                  N/A |\n",
      "| 29%   40C    P8    21W / 250W |   1324MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3528      C   ...da3/envs/pecco/bin/python     1113MiB |\n",
      "|    0   N/A  N/A     54445      C   python                           2235MiB |\n",
      "|    0   N/A  N/A     79228      C   python                           1507MiB |\n",
      "|    1   N/A  N/A     35544      C   python                           1255MiB |\n",
      "|    2   N/A  N/A      3528      C   ...da3/envs/pecco/bin/python     1385MiB |\n",
      "|    3   N/A  N/A     69265      C   python                           1507MiB |\n",
      "|    4   N/A  N/A      3411      C   python                           4457MiB |\n",
      "|    4   N/A  N/A     43240      C   python                           1499MiB |\n",
      "|    5   N/A  N/A      3411      C   python                           1321MiB |\n",
      "|    6   N/A  N/A      3411      C   python                           1321MiB |\n",
      "|    7   N/A  N/A      3411      C   python                           1321MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c791a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pecco",
   "language": "python",
   "name": "pecco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
